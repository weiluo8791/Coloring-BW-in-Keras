{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "# from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "\n",
    "session = keras.backend.get_session()\n",
    "\n",
    "print(\"Python version\",sys.version)\n",
    "print (\"keras version\", keras.__version__)\n",
    "print (\"tensorflow version\", tf.__version__)\n",
    "print (\"numpy version\", np.__version__)\n",
    "# print(\"Eager mode\", tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "X = []\n",
    "for filename in os.listdir('../data/Train/'):\n",
    "    X.append(img_to_array(load_img('../data/Train/'+filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "Xtrain = 1.0/255*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "# print(\"Eager mode\", tf.executing_eagerly())\n",
    "#Load weights\n",
    "inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "inception.load_weights('inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "# inception = InceptionResNetV2(weights='imagenet', include_top=True)\n",
    "inception.graph = tf.compat.v1.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_colorme.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "optz = tf.optimizers.Adam(lr=0.00001)\n",
    "#optz = tf.optimizers.rmsprop(lr=0.00001)\n",
    "model.compile(optimizer=optz, loss='mse', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "# load weights into new model\n",
    "#model.load_weights(\"model.h5\")\n",
    "model.load_weights(\"colorme_weight11.h5\",by_name=True)\n",
    "print(\"Loaded weights from checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1,save_best_only=True,mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embedding\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with session.as_default():\n",
    "        with inception.graph.as_default():\n",
    "            embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.4,\n",
    "        zoom_range=0.4,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 5\n",
    "\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        embed = create_inception_embedding(grayscaled_rgb)\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "model.fit(image_a_b_gen(batch_size), epochs=100, steps_per_epoch=200, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model_colorme.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"colorme_weight12.h5\")\n",
    "\n",
    "#Make predictions on validation images\n",
    "color_me = []\n",
    "for filename in os.listdir('../data/Test/'):\n",
    "    color_me.append(img_to_array(load_img('../data/Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "gray_me = gray2rgb(rgb2gray(1.0/255*color_me))\n",
    "color_me_embed = create_inception_embedding(gray_me)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = model.predict([color_me, color_me_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
